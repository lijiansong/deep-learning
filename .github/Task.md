## Cambricon
- [ ] TODO: research tensorflow compiler XLA, pay attention to its architecture, JIT and llvm (deadline 07/21)
- [ ] TODO: research faster-rcnn, pay attention to its algorithm (deadline 07/21)
- [ ] TODO: build clang & llvm on cambricon server and learn to write a backend for a novel hardware(deadline 07/20)
- [ ] TODO: find out research direction `deep learning programming language or compilier system`, focus on deep learning from the perspective of compilation tech, not deep learning platform e.g. tensorflow, caffe, pytorch and etc (dealine weekends).
- [ ] TODO: learn to write a simple assembler and linker, and try to modify the front-end of clang to support novel syntax feature.
- [ ] TODO: learn the principle of hardware simulator, and find an open-source simulator, try to build & modify it.
- [ ] TODO: document research result xla compilier(dealine weekends).
- [ ] TODO: learn to write an llvm backend by this [link](http://llvm.org/docs/WritingAnLLVMBackend.html); learn gpgpu compiler by this [link](http://llvm.org/docs/CompileCudaWithLLVM.html) and read the source code of faster-rcnn.
- [ ] TODO: review code gen basic concepts
- [ ] TODO: holiday tasks, get familiar with LLVM backend by transplanting instruction set of Cambricon; read the paper of Cambricon instruction set; read the source code of faster rcnn; tensorflow xla compilier document collection
