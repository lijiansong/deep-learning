## Cambricon
- [x] TODO: research tensorflow compiler XLA, pay attention to its architecture, JIT and llvm (deadline 07/21)
- [x] TODO: research faster-rcnn, pay attention to its algorithm (deadline 07/21)
- [x] TODO: build clang & llvm on cambricon server and learn to write a backend for a novel hardware(deadline 07/20)
- [x] TODO: find out research direction `deep learning programming language or compilier system`, focus on deep learning from the perspective of compilation tech, not deep learning platform e.g. tensorflow, caffe, pytorch and etc (dealine weekends).
- [x] TODO: learn to write a simple assembler and linker, and try to modify the front-end of clang to support novel syntax feature.
- [x] TODO: learn the principle of hardware simulator, and find an open-source simulator, try to build & modify it.
- [x] TODO: document research result xla compilier(dealine weekends).
- [x] TODO: learn to write an llvm backend by this [link](http://llvm.org/docs/WritingAnLLVMBackend.html); learn gpgpu compiler by this [link](http://llvm.org/docs/CompileCudaWithLLVM.html) and read the source code of faster-rcnn.
- [x] TODO: review code gen basic concepts
- [x] TODO: holiday tasks, get familiar with LLVM backend by transplanting instruction set of Cambricon; read the paper of Cambricon instruction set; read the source code of faster rcnn; tensorflow xla compilier document collection
- [x] TODO: assume we get the machine code of device, what will do during next step? take this question into consideration? 
- [x] TODO: finish the Demo of the whole tool-chain, communication between host and device
- [ ] TODO: finish `__shared__` descriptor module that passes variables between host and device, by refering to the llvm backend of NVPTX and MIPS
- [ ] TODO: finish the RoI pooling of current assembly version by the designed programing model

